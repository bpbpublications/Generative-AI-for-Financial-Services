{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FSI Use-case: Insurance CoPilot \n",
    "\n",
    "In this example we will explore how GenAI can be used to improve customer experience in a Contact Center setting. \n",
    "\n",
    "## Use-case details\n",
    "Imagine a scenario where customers call in to an Insurance company helpline and asking for information about their Insurance policy. Currently, insurance agents have to find the right insurance policy for the customer, open the document and scan through pages and pages to find the relevant part of the policy corresponding to the customer's questions. In the meantime, the customer has to wait on the call. \n",
    "\n",
    "With Generative AI we can improve the experience of the customer on the call by making it easy for Contact Center agent to find the right policy for the customer and to ask questions to a chatbot based on the insurance policy.\n",
    "\n",
    "## Solution\n",
    "\n",
    "As discussed in Chapter 4, we will implement this use-case using the Retrieval Augmented Generation (RAG) architecture. \n",
    "\n",
    "![architecture diagram](./contact-center-workflow.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting boto3 (from -r requirements.txt (line 1))\n",
      "  Using cached boto3-1.34.84-py3-none-any.whl (139 kB)\n",
      "Collecting langchain (from -r requirements.txt (line 2))\n",
      "  Using cached langchain-0.1.16-py3-none-any.whl (817 kB)\n",
      "Collecting chromadb (from -r requirements.txt (line 3))\n",
      "  Using cached chromadb-0.4.24-py3-none-any.whl (525 kB)\n",
      "Collecting sentence-transformers (from -r requirements.txt (line 4))\n",
      "  Using cached sentence_transformers-2.6.1-py3-none-any.whl (163 kB)\n",
      "Collecting tiktoken (from -r requirements.txt (line 5))\n",
      "  Using cached tiktoken-0.6.0-cp311-cp311-macosx_10_9_x86_64.whl (999 kB)\n",
      "Collecting pypdf (from -r requirements.txt (line 6))\n",
      "  Using cached pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
      "Collecting botocore<1.35.0,>=1.34.84 (from boto3->-r requirements.txt (line 1))\n",
      "  Using cached botocore-1.34.84-py3-none-any.whl (12.1 MB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3->-r requirements.txt (line 1))\n",
      "  Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3->-r requirements.txt (line 1))\n",
      "  Using cached s3transfer-0.10.1-py3-none-any.whl (82 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain->-r requirements.txt (line 2))\n",
      "  Using cached PyYAML-6.0.1-cp311-cp311-macosx_10_9_x86_64.whl (187 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain->-r requirements.txt (line 2))\n",
      "  Using cached SQLAlchemy-2.0.29-cp311-cp311-macosx_10_9_x86_64.whl (2.1 MB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain->-r requirements.txt (line 2))\n",
      "  Using cached aiohttp-3.9.4-cp311-cp311-macosx_10_9_x86_64.whl (402 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain->-r requirements.txt (line 2))\n",
      "  Using cached dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain->-r requirements.txt (line 2))\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Collecting langchain-community<0.1,>=0.0.32 (from langchain->-r requirements.txt (line 2))\n",
      "  Using cached langchain_community-0.0.33-py3-none-any.whl (1.9 MB)\n",
      "Collecting langchain-core<0.2.0,>=0.1.42 (from langchain->-r requirements.txt (line 2))\n",
      "  Using cached langchain_core-0.1.43-py3-none-any.whl (289 kB)\n",
      "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain->-r requirements.txt (line 2))\n",
      "  Using cached langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain->-r requirements.txt (line 2))\n",
      "  Using cached langsmith-0.1.48-py3-none-any.whl (113 kB)\n",
      "Collecting numpy<2,>=1 (from langchain->-r requirements.txt (line 2))\n",
      "  Using cached numpy-1.26.4-cp311-cp311-macosx_10_9_x86_64.whl (20.6 MB)\n",
      "Collecting pydantic<3,>=1 (from langchain->-r requirements.txt (line 2))\n",
      "  Using cached pydantic-2.7.0-py3-none-any.whl (407 kB)\n",
      "Collecting requests<3,>=2 (from langchain->-r requirements.txt (line 2))\n",
      "  Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Collecting tenacity<9.0.0,>=8.1.0 (from langchain->-r requirements.txt (line 2))\n",
      "  Using cached tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Collecting build>=1.0.3 (from chromadb->-r requirements.txt (line 3))\n",
      "  Using cached build-1.2.1-py3-none-any.whl (21 kB)\n",
      "Collecting chroma-hnswlib==0.7.3 (from chromadb->-r requirements.txt (line 3))\n",
      "  Using cached chroma_hnswlib-0.7.3-cp311-cp311-macosx_10_9_x86_64.whl (221 kB)\n",
      "Collecting fastapi>=0.95.2 (from chromadb->-r requirements.txt (line 3))\n",
      "  Using cached fastapi-0.110.1-py3-none-any.whl (91 kB)\n",
      "Collecting uvicorn[standard]>=0.18.3 (from chromadb->-r requirements.txt (line 3))\n",
      "  Using cached uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
      "Collecting posthog>=2.4.0 (from chromadb->-r requirements.txt (line 3))\n",
      "  Using cached posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n",
      "Collecting typing-extensions>=4.5.0 (from chromadb->-r requirements.txt (line 3))\n",
      "  Using cached typing_extensions-4.11.0-py3-none-any.whl (34 kB)\n",
      "Collecting pulsar-client>=3.1.0 (from chromadb->-r requirements.txt (line 3))\n",
      "  Using cached pulsar_client-3.5.0-cp311-cp311-macosx_10_15_universal2.whl (11.0 MB)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb->-r requirements.txt (line 3))\n",
      "  Using cached onnxruntime-1.17.3-cp311-cp311-macosx_11_0_universal2.whl (14.8 MB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb->-r requirements.txt (line 3))\n",
      "  Using cached opentelemetry_api-1.24.0-py3-none-any.whl (60 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb->-r requirements.txt (line 3))\n",
      "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.24.0-py3-none-any.whl (18 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb->-r requirements.txt (line 3))\n",
      "  Using cached opentelemetry_instrumentation_fastapi-0.45b0-py3-none-any.whl (11 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb->-r requirements.txt (line 3))\n",
      "  Using cached opentelemetry_sdk-1.24.0-py3-none-any.whl (106 kB)\n",
      "Collecting tokenizers>=0.13.2 (from chromadb->-r requirements.txt (line 3))\n",
      "  Using cached tokenizers-0.15.2-cp311-cp311-macosx_10_12_x86_64.whl (2.6 MB)\n",
      "Collecting pypika>=0.48.9 (from chromadb->-r requirements.txt (line 3))\n",
      "  Using cached PyPika-0.48.9-py2.py3-none-any.whl\n",
      "Collecting tqdm>=4.65.0 (from chromadb->-r requirements.txt (line 3))\n",
      "  Using cached tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "Collecting overrides>=7.3.1 (from chromadb->-r requirements.txt (line 3))\n",
      "  Using cached overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Collecting importlib-resources (from chromadb->-r requirements.txt (line 3))\n",
      "  Using cached importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
      "Collecting grpcio>=1.58.0 (from chromadb->-r requirements.txt (line 3))\n",
      "  Using cached grpcio-1.62.1-cp311-cp311-macosx_10_10_universal2.whl (10.0 MB)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb->-r requirements.txt (line 3))\n",
      "  Using cached bcrypt-4.1.2-cp39-abi3-macosx_10_12_universal2.whl (528 kB)\n",
      "Collecting typer>=0.9.0 (from chromadb->-r requirements.txt (line 3))\n",
      "  Using cached typer-0.12.3-py3-none-any.whl (47 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb->-r requirements.txt (line 3))\n",
      "  Using cached kubernetes-29.0.0-py2.py3-none-any.whl (1.6 MB)\n",
      "Collecting mmh3>=4.0.1 (from chromadb->-r requirements.txt (line 3))\n",
      "  Using cached mmh3-4.1.0-cp311-cp311-macosx_10_9_x86_64.whl (29 kB)\n",
      "Collecting orjson>=3.9.12 (from chromadb->-r requirements.txt (line 3))\n",
      "  Using cached orjson-3.10.1-cp311-cp311-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (250 kB)\n",
      "Collecting transformers<5.0.0,>=4.32.0 (from sentence-transformers->-r requirements.txt (line 4))\n",
      "  Using cached transformers-4.39.3-py3-none-any.whl (8.8 MB)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers->-r requirements.txt (line 4))\n",
      "  Using cached torch-2.2.2-cp311-none-macosx_10_9_x86_64.whl (150.8 MB)\n",
      "Collecting scikit-learn (from sentence-transformers->-r requirements.txt (line 4))\n",
      "  Using cached scikit_learn-1.4.2-cp311-cp311-macosx_10_9_x86_64.whl (11.6 MB)\n",
      "Collecting scipy (from sentence-transformers->-r requirements.txt (line 4))\n",
      "  Using cached scipy-1.13.0-cp311-cp311-macosx_10_9_x86_64.whl (39.3 MB)\n",
      "Collecting huggingface-hub>=0.15.1 (from sentence-transformers->-r requirements.txt (line 4))\n",
      "  Using cached huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n",
      "Collecting Pillow (from sentence-transformers->-r requirements.txt (line 4))\n",
      "  Using cached pillow-10.3.0-cp311-cp311-macosx_10_10_x86_64.whl (3.5 MB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken->-r requirements.txt (line 5))\n",
      "  Using cached regex-2023.12.25-cp311-cp311-macosx_10_9_x86_64.whl (296 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 2))\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 2))\n",
      "  Using cached attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 2))\n",
      "  Using cached frozenlist-1.4.1-cp311-cp311-macosx_10_9_x86_64.whl (55 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 2))\n",
      "  Using cached multidict-6.0.5-cp311-cp311-macosx_10_9_x86_64.whl (30 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 2))\n",
      "  Using cached yarl-1.9.4-cp311-cp311-macosx_10_9_x86_64.whl (83 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/arnavk/.pyenv/versions/3.11.4/lib/python3.11/site-packages (from botocore<1.35.0,>=1.34.84->boto3->-r requirements.txt (line 1)) (2.8.2)\n",
      "Collecting urllib3!=2.2.0,<3,>=1.25.4 (from botocore<1.35.0,>=1.34.84->boto3->-r requirements.txt (line 1))\n",
      "  Using cached urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "Requirement already satisfied: packaging>=19.1 in /Users/arnavk/.pyenv/versions/3.11.4/lib/python3.11/site-packages (from build>=1.0.3->chromadb->-r requirements.txt (line 3)) (23.2)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb->-r requirements.txt (line 3))\n",
      "  Using cached pyproject_hooks-1.0.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain->-r requirements.txt (line 2))\n",
      "  Using cached marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain->-r requirements.txt (line 2))\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Collecting starlette<0.38.0,>=0.37.2 (from fastapi>=0.95.2->chromadb->-r requirements.txt (line 3))\n",
      "  Using cached starlette-0.37.2-py3-none-any.whl (71 kB)\n",
      "Collecting filelock (from huggingface-hub>=0.15.1->sentence-transformers->-r requirements.txt (line 4))\n",
      "  Using cached filelock-3.13.4-py3-none-any.whl (11 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.15.1->sentence-transformers->-r requirements.txt (line 4))\n",
      "  Using cached fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain->-r requirements.txt (line 2))\n",
      "  Using cached jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
      "Collecting certifi>=14.05.14 (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 3))\n",
      "  Using cached certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/arnavk/.pyenv/versions/3.11.4/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 3)) (1.16.0)\n",
      "Collecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 3))\n",
      "  Using cached google_auth-2.29.0-py2.py3-none-any.whl (189 kB)\n",
      "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 3))\n",
      "  Using cached websocket_client-1.7.0-py3-none-any.whl (58 kB)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 3))\n",
      "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 3))\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 3))\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 3))\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 3))\n",
      "  Downloading protobuf-5.26.1-cp37-abi3-macosx_10_9_universal2.whl (404 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.0/404.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting sympy (from onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 3))\n",
      "  Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb->-r requirements.txt (line 3))\n",
      "  Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting importlib-metadata<=7.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb->-r requirements.txt (line 3))\n",
      "  Using cached importlib_metadata-7.0.0-py3-none-any.whl (23 kB)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 3))\n",
      "  Using cached googleapis_common_protos-1.63.0-py2.py3-none-any.whl (229 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.24.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 3))\n",
      "  Using cached opentelemetry_exporter_otlp_proto_common-1.24.0-py3-none-any.whl (17 kB)\n",
      "Collecting opentelemetry-proto==1.24.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 3))\n",
      "  Using cached opentelemetry_proto-1.24.0-py3-none-any.whl (50 kB)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 3))\n",
      "  Using cached protobuf-4.25.3-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 3))\n",
      "  Using cached opentelemetry_instrumentation_asgi-0.45b0-py3-none-any.whl (14 kB)\n",
      "Collecting opentelemetry-instrumentation==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 3))\n",
      "  Using cached opentelemetry_instrumentation-0.45b0-py3-none-any.whl (28 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 3))\n",
      "  Using cached opentelemetry_semantic_conventions-0.45b0-py3-none-any.whl (36 kB)\n",
      "Collecting opentelemetry-util-http==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 3))\n",
      "  Using cached opentelemetry_util_http-0.45b0-py3-none-any.whl (6.9 kB)\n",
      "Requirement already satisfied: setuptools>=16.0 in /Users/arnavk/.pyenv/versions/3.11.4/lib/python3.11/site-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 3)) (65.5.0)\n",
      "Collecting wrapt<2.0.0,>=1.0.0 (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 3))\n",
      "  Using cached wrapt-1.16.0-cp311-cp311-macosx_10_9_x86_64.whl (37 kB)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 3))\n",
      "  Using cached asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb->-r requirements.txt (line 3))\n",
      "  Using cached monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb->-r requirements.txt (line 3))\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1->langchain->-r requirements.txt (line 2))\n",
      "  Using cached annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Collecting pydantic-core==2.18.1 (from pydantic<3,>=1->langchain->-r requirements.txt (line 2))\n",
      "  Using cached pydantic_core-2.18.1-cp311-cp311-macosx_10_12_x86_64.whl (1.9 MB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2->langchain->-r requirements.txt (line 2))\n",
      "  Using cached charset_normalizer-3.3.2-cp311-cp311-macosx_10_9_x86_64.whl (121 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2->langchain->-r requirements.txt (line 2))\n",
      "  Using cached idna-3.7-py3-none-any.whl (66 kB)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain->-r requirements.txt (line 2))\n",
      "  Using cached greenlet-3.0.3-cp311-cp311-macosx_11_0_universal2.whl (271 kB)\n",
      "Collecting networkx (from torch>=1.11.0->sentence-transformers->-r requirements.txt (line 4))\n",
      "  Using cached networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "Collecting jinja2 (from torch>=1.11.0->sentence-transformers->-r requirements.txt (line 4))\n",
      "  Using cached Jinja2-3.1.3-py3-none-any.whl (133 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.32.0->sentence-transformers->-r requirements.txt (line 4))\n",
      "  Using cached safetensors-0.4.3-cp311-cp311-macosx_10_12_x86_64.whl (415 kB)\n",
      "Collecting click>=8.0.0 (from typer>=0.9.0->chromadb->-r requirements.txt (line 3))\n",
      "  Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb->-r requirements.txt (line 3))\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Collecting rich>=10.11.0 (from typer>=0.9.0->chromadb->-r requirements.txt (line 3))\n",
      "  Using cached rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "Collecting h11>=0.8 (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 3))\n",
      "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 3))\n",
      "  Using cached httptools-0.6.1-cp311-cp311-macosx_10_9_x86_64.whl (75 kB)\n",
      "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 3))\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 3))\n",
      "  Using cached uvloop-0.19.0-cp311-cp311-macosx_10_9_x86_64.whl (746 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 3))\n",
      "  Using cached watchfiles-0.21.0-cp311-cp311-macosx_10_7_x86_64.whl (428 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 3))\n",
      "  Using cached websockets-12.0-cp311-cp311-macosx_10_9_x86_64.whl (121 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->sentence-transformers->-r requirements.txt (line 4))\n",
      "  Using cached joblib-1.4.0-py3-none-any.whl (301 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn->sentence-transformers->-r requirements.txt (line 4))\n",
      "  Using cached threadpoolctl-3.4.0-py3-none-any.whl (17 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 3))\n",
      "  Using cached cachetools-5.3.3-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 3))\n",
      "  Using cached pyasn1_modules-0.4.0-py3-none-any.whl (181 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 3))\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting zipp>=0.5 (from importlib-metadata<=7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb->-r requirements.txt (line 3))\n",
      "  Using cached zipp-3.18.1-py3-none-any.whl (8.2 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer>=0.9.0->chromadb->-r requirements.txt (line 3))\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/arnavk/.pyenv/versions/3.11.4/lib/python3.11/site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb->-r requirements.txt (line 3)) (2.17.2)\n",
      "Collecting anyio<5,>=3.4.0 (from starlette<0.38.0,>=0.37.2->fastapi>=0.95.2->chromadb->-r requirements.txt (line 3))\n",
      "  Using cached anyio-4.3.0-py3-none-any.whl (85 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain->-r requirements.txt (line 2))\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 3))\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.11.0->sentence-transformers->-r requirements.txt (line 4))\n",
      "  Using cached MarkupSafe-2.1.5-cp311-cp311-macosx_10_9_x86_64.whl (14 kB)\n",
      "Collecting mpmath>=0.19 (from sympy->onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 3))\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Collecting sniffio>=1.1 (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi>=0.95.2->chromadb->-r requirements.txt (line 3))\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb->-r requirements.txt (line 3))\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 3))\n",
      "  Using cached pyasn1-0.6.0-py2.py3-none-any.whl (85 kB)\n",
      "Installing collected packages: pypika, mpmath, monotonic, mmh3, flatbuffers, zipp, wrapt, websockets, websocket-client, uvloop, urllib3, typing-extensions, tqdm, threadpoolctl, tenacity, sympy, sniffio, shellingham, safetensors, regex, PyYAML, python-dotenv, pyproject_hooks, pypdf, pyasn1, protobuf, Pillow, overrides, orjson, opentelemetry-util-http, opentelemetry-semantic-conventions, oauthlib, numpy, networkx, mypy-extensions, multidict, mdurl, marshmallow, MarkupSafe, jsonpointer, joblib, jmespath, importlib-resources, idna, humanfriendly, httptools, h11, grpcio, greenlet, fsspec, frozenlist, filelock, click, charset-normalizer, certifi, cachetools, bcrypt, backoff, attrs, asgiref, annotated-types, yarl, uvicorn, typing-inspect, SQLAlchemy, scipy, rsa, requests, pydantic-core, pyasn1-modules, pulsar-client, opentelemetry-proto, markdown-it-py, jsonpatch, jinja2, importlib-metadata, googleapis-common-protos, deprecated, coloredlogs, chroma-hnswlib, build, botocore, anyio, aiosignal, watchfiles, torch, tiktoken, starlette, scikit-learn, s3transfer, rich, requests-oauthlib, pydantic, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, onnxruntime, huggingface-hub, google-auth, dataclasses-json, aiohttp, typer, tokenizers, opentelemetry-sdk, opentelemetry-instrumentation, langsmith, kubernetes, fastapi, boto3, transformers, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, langchain-core, sentence-transformers, opentelemetry-instrumentation-fastapi, langchain-text-splitters, langchain-community, langchain, chromadb\n",
      "Successfully installed MarkupSafe-2.1.5 Pillow-10.3.0 PyYAML-6.0.1 SQLAlchemy-2.0.29 aiohttp-3.9.4 aiosignal-1.3.1 annotated-types-0.6.0 anyio-4.3.0 asgiref-3.8.1 attrs-23.2.0 backoff-2.2.1 bcrypt-4.1.2 boto3-1.34.84 botocore-1.34.84 build-1.2.1 cachetools-5.3.3 certifi-2024.2.2 charset-normalizer-3.3.2 chroma-hnswlib-0.7.3 chromadb-0.4.24 click-8.1.7 coloredlogs-15.0.1 dataclasses-json-0.6.4 deprecated-1.2.14 fastapi-0.110.1 filelock-3.13.4 flatbuffers-24.3.25 frozenlist-1.4.1 fsspec-2024.3.1 google-auth-2.29.0 googleapis-common-protos-1.63.0 greenlet-3.0.3 grpcio-1.62.1 h11-0.14.0 httptools-0.6.1 huggingface-hub-0.22.2 humanfriendly-10.0 idna-3.7 importlib-metadata-7.0.0 importlib-resources-6.4.0 jinja2-3.1.3 jmespath-1.0.1 joblib-1.4.0 jsonpatch-1.33 jsonpointer-2.4 kubernetes-29.0.0 langchain-0.1.16 langchain-community-0.0.33 langchain-core-0.1.43 langchain-text-splitters-0.0.1 langsmith-0.1.48 markdown-it-py-3.0.0 marshmallow-3.21.1 mdurl-0.1.2 mmh3-4.1.0 monotonic-1.6 mpmath-1.3.0 multidict-6.0.5 mypy-extensions-1.0.0 networkx-3.3 numpy-1.26.4 oauthlib-3.2.2 onnxruntime-1.17.3 opentelemetry-api-1.24.0 opentelemetry-exporter-otlp-proto-common-1.24.0 opentelemetry-exporter-otlp-proto-grpc-1.24.0 opentelemetry-instrumentation-0.45b0 opentelemetry-instrumentation-asgi-0.45b0 opentelemetry-instrumentation-fastapi-0.45b0 opentelemetry-proto-1.24.0 opentelemetry-sdk-1.24.0 opentelemetry-semantic-conventions-0.45b0 opentelemetry-util-http-0.45b0 orjson-3.10.1 overrides-7.7.0 posthog-3.5.0 protobuf-4.25.3 pulsar-client-3.5.0 pyasn1-0.6.0 pyasn1-modules-0.4.0 pydantic-2.7.0 pydantic-core-2.18.1 pypdf-4.2.0 pypika-0.48.9 pyproject_hooks-1.0.0 python-dotenv-1.0.1 regex-2023.12.25 requests-2.31.0 requests-oauthlib-2.0.0 rich-13.7.1 rsa-4.9 s3transfer-0.10.1 safetensors-0.4.3 scikit-learn-1.4.2 scipy-1.13.0 sentence-transformers-2.6.1 shellingham-1.5.4 sniffio-1.3.1 starlette-0.37.2 sympy-1.12 tenacity-8.2.3 threadpoolctl-3.4.0 tiktoken-0.6.0 tokenizers-0.15.2 torch-2.2.2 tqdm-4.66.2 transformers-4.39.3 typer-0.12.3 typing-extensions-4.11.0 typing-inspect-0.9.0 urllib3-2.2.1 uvicorn-0.29.0 uvloop-0.19.0 watchfiles-0.21.0 websocket-client-1.7.0 websockets-12.0 wrapt-1.16.0 yarl-1.9.4 zipp-3.18.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Installing required libraries\n",
    "!pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing the policy documents \n",
    "\n",
    "As the first step we prepare and index the documents into a vector DB. In this example we will use a local ChromaDB vector database, but for a full deployment you can use other open source VectorDB such as OpenSearch, pgVector for PostgreSQL or proprietary ones such as Pinecone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import TextLoader, DirectoryLoader, PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter, TokenTextSplitter\n",
    "\n",
    "# from langchain.llms import Bedrock\n",
    "from langchain_community.llms import Bedrock\n",
    "from langchain.embeddings import HuggingFaceEmbeddings \n",
    "\n",
    "import os\n",
    "import boto3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example we are using the following models:\n",
    "\n",
    "* LLM: Llama 2 13b Chat model available through Amazon Bedrock\n",
    "* Embedding: Sentence Transformers embedding available through HuggingFace\n",
    "\n",
    "You can modify this example and call your favorite LLM and Embedding model as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_MODEL_ID = \"meta.llama2-13b-chat-v1\"\n",
    "\n",
    "def get_llm(model_id=DEFAULT_MODEL_ID, aws_region=\"us-east-1\"):\n",
    "    bedrock = boto3.client(service_name='bedrock-runtime', region_name=aws_region)\n",
    "    llm = Bedrock(\n",
    "        model_id=model_id,\n",
    "        region_name=aws_region,\n",
    "        client=bedrock\n",
    "    )\n",
    "    return llm\n",
    "\n",
    "\n",
    "def get_embedding_model():\n",
    "    return HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write a utility function that does all the steps we need for indexing documents: \n",
    "\n",
    "* loads PDF files from a directory, \n",
    "* splits it into chunks,\n",
    "* embed and store the documents into local ChromaDB vector database using Langchain provided interface \n",
    "\n",
    "In this example we are using a publicly available sample Insurance Policy available from AXA Insurance website [here](http://www.axainsurance.com/home/policy-wording/policywording_153.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_docs(file_path, embeddings, chunk_size = 1000):\n",
    "    # Loading text from local files\n",
    "    isDirectory = os.path.isdir(file_path)\n",
    "    if isDirectory:\n",
    "        loader = DirectoryLoader(file_path, loader_cls=PyPDFLoader, show_progress=True)    \n",
    "    else:\n",
    "        loader = PyPDFLoader(file_path, encoding='utf8')\n",
    "    \n",
    "    print(\"Loading documents from path:\", file_path)\n",
    "    documents = loader.load()\n",
    "\n",
    "    print(\"Splitting documents. chunk_size=\", chunk_size)\n",
    "    # For splitting by characters, use CharacterTextSplitter class\n",
    "    # text_splitter = CharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=5000)\n",
    "    # For splitting by tokens, use TokenTextSplitter class\n",
    "    text_splitter = TokenTextSplitter(chunk_size=chunk_size, chunk_overlap=50)\n",
    "\n",
    "    # Split the documents and save the first chunk\n",
    "    texts = text_splitter.split_documents(documents)\n",
    "\n",
    "    print(\"Calculating embedding and storing in vector db\")\n",
    "    db = Chroma.from_documents(texts, embeddings)\n",
    "    return db\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load and index the documents in our local folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arnavk/.pyenv/versions/3.11.4/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading documents from path: files/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting documents. chunk_size= 1000\n",
      "Calculating embedding and storing in vector db\n"
     ]
    }
   ],
   "source": [
    "CHUNK_SIZE = 1000\n",
    "\n",
    "db = index_docs(\n",
    "    file_path=\"files/\",\n",
    "    embeddings=get_embedding_model(),\n",
    "    chunk_size = CHUNK_SIZE, \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying the policy documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_docs(user_query, db, k=2):\n",
    "    # Obtain top-k similar chunks from VectorDB\n",
    "    docs = db.similarity_search_with_score(user_query)[:k]\n",
    "\n",
    "    # For each document chunk retrieved capture the text and source metadata for displaying references\n",
    "    docs = [{\"content\": x[0].page_content, \"source\":x[0].metadata[\"source\"]} for x in docs]\n",
    "\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "QNA_PROMPT = \"\"\"\n",
    "\\n\\nHuman: You are a financial AI, an artificial intelligence developed to answer questions about finances and investments. \n",
    "Use the following documents and the information contained therein to answer the following question and provide relevant information: \"{question}\".\n",
    "\n",
    "The text of the document is within the <text></text> XML tags: {documents}\n",
    "\n",
    "Use these documents to formulate your own answer to the question \"{question}\", as if you were directly answering the question. Ensure that your answer is correct and does not contain any information that cannot be directly taken from the documents. Do not directly cite the document or metadata.\n",
    "\n",
    "Assistant:\"\"\"\n",
    "\n",
    "HUMAN_PROMPT = \"Human:\"\n",
    "\n",
    "def ask_llm(user_query, docs, llm):\n",
    "    qna_prompt = QNA_PROMPT.format(question = user_query, documents=docs)\n",
    "    print(\"QNA Prompt: \",qna_prompt)\n",
    "    answer = llm.invoke(\n",
    "        input=qna_prompt,\n",
    "        stop=[HUMAN_PROMPT]\n",
    "    )\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QNA Prompt:  \n",
      "\n",
      "\n",
      "Human: You are a financial AI, an artificial intelligence developed to answer questions about finances and investments. \n",
      "Use the following documents and the information contained therein to answer the following question and provide relevant information: \"What type of accidental breakage is covered in Home Insurance?\".\n",
      "\n",
      "The text of the document is within the <text></text> XML tags: [{'content': ' \\nADH 15. 10a \\n6 Accidental Damage (optional extra)  \\nYour policy schedule will show if you have chosen this section.  \\n \\n7. Accidental damage to cables, drain inspection \\ncovers and underground drains, pipes or tanks \\nproviding services to or from the home  and for \\nwhich you are responsible.  \\n \\nWe will also pay up to the limit for any one claim \\nfor necessary and reasonable costs that you \\nincur in finding the source of the damage to the \\nhome .  This includes reinstating any wall, floor, \\nceiling, drive, fence or path removed or damaged \\nduring the search  \\n \\nLimit – please refer to your schedule  \\n \\n8. Accidental damage or loss to the buildings  \\nincluding accidental breakage of:  \\n• fixed glass in windows, doors, fanlights, \\nskylights, greenhouses, conservatories and \\nverandas;  \\n• fixed ceramic hobs and ceramic tops of fixed \\ncookers;  \\n• fixed sanitary ware and bathroom fittings  \\n  \\nLoss or damage to pitch fibre drains caused by \\ninherent defects in the design, material, construction, \\nor installation of the pipes and drains.  \\n \\nIf it is discovered that the cause is not accidental \\ndamage then unless one of the other causes is \\noperative there will be no cover.  \\n \\n \\n \\n \\n \\n \\n \\nAccidental Damage does not cover loss or damage \\ncaused:  \\n• by frost;  \\n• by or arising from faulty workmanship, defective \\ndesign or use of defective materials;  \\n• by insects or vermin ; \\n• by chewing, scratching, tearing or fouling by \\nyour  domestic pets;  \\n• by mechanical or electrical breakdown or \\nfailure;  \\n• to gates, hedges and fences;  \\n• to drives, patios and paths unless your  home  \\nhas been damaged at the same time and by the \\nsame cause.  \\n \\n  \\nCauses  \\n \\nWhat your policy covers:   \\n \\nWhat your policy does not cover:  \\nYour  policy  covers the buildings  for loss or damage \\nresulting from any of the following:  \\n \\n1. Storm  or flood  \\n \\n \\n \\n \\n \\n  \\n \\n \\nLoss or damage:  \\n• to gates, hedges and fences;  \\n• to drives, patios and paths unless your  home  \\nhas been damaged at the same time and by the \\nsame cause;  \\n• by storm  to radio or television aerials or satellite \\ndishes.  ', 'source': 'files/axa_sample_policy.pdf'}, {'content': ' \\nADH 15. 10a \\n50 Cover 2 – Consumer Defence  \\n \\nWhat is insured : \\nCosts  to defend a Legal Action  brought against You following a breach of a contract You have for selling \\nYour own personal goods . The contract must have been made after You  first purchased this insurance \\nunless You have held this or equivalent cover with Us or another insurer continuously from or before the date \\non which the agreement was made.  \\nWhat is not insured : \\nClaims:  \\na) Where the amount in dispute is less than £125 plus VAT  \\nb) Where the breach of contract occurred before You  purchased this insurance  \\nc) In respect of works undertaken or to be undertaken by or under the order of any government, public or \\nlocal authority  \\nd) Arising from the sale or purchase of Your  main home  \\ne) Relating to a lease tenancy or licence to use property or land  \\n \\n \\nCover 3 – Personal Injury  \\n \\nWhat is insured :  \\nCosts  to pursue a Legal Action  following an accident resulting in Your  personal injury or death against the \\nperson or organisation directly responsible.  \\nWhat is not insured : \\nClaims:  \\na) Arising from  medical or clinical treatment, advice, assistance or care  \\nb) For stress, psychological or emotional injury  unless it arises from you  suffering physical injury  \\nc) For illness, personal injury or death caused gradually and not caused by a specific sudden event  \\nd) Involving a vehicle owned or driven by You  \\n \\nCover 4 – Clinical Negligence  \\n \\nWhat is insured :  \\nCosts to pursue a Legal Action for damages following clinical negligence resulting in Your personal \\ninjury or death against the person or organisation directly responsible.  \\nWhat is not insured : \\nClaims for stress, psychological or emotional injury  unless it arises from You suffering physical injury . \\n ', 'source': 'files/axa_sample_policy.pdf'}]\n",
      "\n",
      "Use these documents to formulate your own answer to the question \"What type of accidental breakage is covered in Home Insurance?\", as if you were directly answering the question. Ensure that your answer is correct and does not contain any information that cannot be directly taken from the documents. Do not directly cite the document or metadata.\n",
      "\n",
      "Assistant:\n",
      "Answer:   Sure, I'd be happy to help! Based on the documents you provided, it appears that accidental breakage is covered in Home Insurance under the \"Accidental Damage\" section. This includes accidental breakage of fixed glass in windows, doors, fanlights, skylights, greenhouses, conservatories, and verandas. Additionally, it covers accidental damage to fixed ceramic hobs and ceramic tops of fixed cookers, as well as fixed sanitary ware and bathroom fittings. However, it's important to note that there are certain exclusions and limitations to this coverage, such as damage caused by frost, insects, or vermin, and damage to gates, hedges, and fences.\n",
      "# Source: axa_sample_policy.pdf\n",
      " \n",
      "ADH 15. 10a \n",
      "6 Accidental Damage (optional extra)  \n",
      "Your policy schedule will show if you have chosen this section.  \n",
      " \n",
      "7. Accidental damage to cables, drain inspection \n",
      "covers and underground drains, pipes or tanks \n",
      "providing services to or from the home  and for \n",
      "which you are responsible.  \n",
      " \n",
      "We will also pay up to the limit for any one claim \n",
      "for necessary and reasonable costs that you \n",
      "incur in finding the source of the damage to the \n",
      "home .  This includes reinstating any wall, floor, \n",
      "ceiling, drive, fence or path removed or damaged \n",
      "during the search  \n",
      " \n",
      "Limit – please refer to your schedule  \n",
      " \n",
      "8. Accidental damage or loss to the buildings  \n",
      "including accidental breakage of:  \n",
      "• fixed glass in windows, doors, fanlights, \n",
      "skylights, greenhouses, conservatories and \n",
      "verandas;  \n",
      "• fixed ceramic hobs and ceramic tops of fixed \n",
      "cookers;  \n",
      "• fixed sanitary ware and bathroom fittings  \n",
      "  \n",
      "Loss or damage to pitch fibre drains caused by \n",
      "inherent defects in the design, material, construction, \n",
      "or installation of the pipes and drains.  \n",
      " \n",
      "If it is discovered that the cause is not accidental \n",
      "damage then unless one of the other causes is \n",
      "operative there will be no cover.  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Accidental Damage does not cover loss or damage \n",
      "caused:  \n",
      "• by frost;  \n",
      "• by or arising from faulty workmanship, defective \n",
      "design or use of defective materials;  \n",
      "• by insects or vermin ; \n",
      "• by chewing, scratching, tearing or fouling by \n",
      "your  domestic pets;  \n",
      "• by mechanical or electrical breakdown or \n",
      "failure;  \n",
      "• to gates, hedges and fences;  \n",
      "• to drives, patios and paths unless your  home  \n",
      "has been damaged at the same time and by the \n",
      "same cause.  \n",
      " \n",
      "  \n",
      "Causes  \n",
      " \n",
      "What your policy covers:   \n",
      " \n",
      "What your policy does not cover:  \n",
      "Your  policy  covers the buildings  for loss or damage \n",
      "resulting from any of the following:  \n",
      " \n",
      "1. Storm  or flood  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "  \n",
      " \n",
      " \n",
      "Loss or damage:  \n",
      "• to gates, hedges and fences;  \n",
      "• to drives, patios and paths unless your  home  \n",
      "has been damaged...\n",
      "# Source: axa_sample_policy.pdf\n",
      " \n",
      "ADH 15. 10a \n",
      "50 Cover 2 – Consumer Defence  \n",
      " \n",
      "What is insured : \n",
      "Costs  to defend a Legal Action  brought against You following a breach of a contract You have for selling \n",
      "Your own personal goods . The contract must have been made after You  first purchased this insurance \n",
      "unless You have held this or equivalent cover with Us or another insurer continuously from or before the date \n",
      "on which the agreement was made.  \n",
      "What is not insured : \n",
      "Claims:  \n",
      "a) Where the amount in dispute is less than £125 plus VAT  \n",
      "b) Where the breach of contract occurred before You  purchased this insurance  \n",
      "c) In respect of works undertaken or to be undertaken by or under the order of any government, public or \n",
      "local authority  \n",
      "d) Arising from the sale or purchase of Your  main home  \n",
      "e) Relating to a lease tenancy or licence to use property or land  \n",
      " \n",
      " \n",
      "Cover 3 – Personal Injury  \n",
      " \n",
      "What is insured :  \n",
      "Costs  to pursue a Legal Action  following an accident resulting in Your  personal injury or death against the \n",
      "person or organisation directly responsible.  \n",
      "What is not insured : \n",
      "Claims:  \n",
      "a) Arising from  medical or clinical treatment, advice, assistance or care  \n",
      "b) For stress, psychological or emotional injury  unless it arises from you  suffering physical injury  \n",
      "c) For illness, personal injury or death caused gradually and not caused by a specific sudden event  \n",
      "d) Involving a vehicle owned or driven by You  \n",
      " \n",
      "Cover 4 – Clinical Negligence  \n",
      " \n",
      "What is insured :  \n",
      "Costs to pursue a Legal Action for damages following clinical negligence resulting in Your personal \n",
      "injury or death against the person or organisation directly responsible.  \n",
      "What is not insured : \n",
      "Claims for stress, psychological or emotional injury  unless it arises from You suffering physical injury . \n",
      " ...\n"
     ]
    }
   ],
   "source": [
    "user_query = \"What type of accidental breakage is covered in Home Insurance?\"\n",
    "\n",
    "# First search vector db to retreive chunks of relevant information from documents.\n",
    "docs = search_docs(user_query, db)\n",
    "\n",
    "# Ask the question to LLM, by augmenting the query with relevant chunks of information from documents.\n",
    "llm = get_llm()\n",
    "answer = ask_llm(user_query, docs, llm)\n",
    "\n",
    "print(\"Answer: \", answer)\n",
    "for doc in docs:\n",
    "    print(\"# Source: \" + doc[\"source\"].split(\"/\")[-1])\n",
    "    print(doc[\"content\"][:2000].replace(\"#\", \"\") + \"...\")   # display only first 2k chars for brevity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
